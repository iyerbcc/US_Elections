{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d980e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/11 14:11:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umaiyer/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\", \"elect\")\n",
    "from pyspark import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0137cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,concat,concat_ws, expr,overlay, regexp_replace, translate, udf,upper, when\n",
    "\n",
    "from pyspark.sql.types import BooleanType,DateType,IntegerType,StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2148888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "year19 = ['94','96','98']\n",
    "year20 = ['00','02','04','06','08','10','12','14','16','18','20']\n",
    "for year in year19:\n",
    "    df[year]=sqlContext.read.csv('clean3_election_data/tab_19'+year+'.csv',header=False).\\\n",
    "        toDF('index','Categories','Total_Population_19'+year,'Total_Registered_19'+year,'Total_Voted_19'+year)\n",
    "    df[year] = df[year].na.drop(subset=['index'])\n",
    "\n",
    "for year in year20:\n",
    "    df[year]=sqlContext.read.csv('clean3_election_data/tab_20'+year+'.csv',header=False).\\\n",
    "        toDF('index','Categories','Total_Population_20'+year,'Total_Registered_20'+year,'Total_Voted_20'+year)\n",
    "    df[year] = df[year].na.drop(subset=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242a0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = df['94'].join(df['96'], df['94'].index == df['96'].index, 'inner').\\\n",
    "    join(df['98'], df['94'].index==df['98'].index, 'inner').\\\n",
    "    join(df['00'], df['94'].index==df['00'].index, 'inner').\\\n",
    "    join(df['02'], df['94'].index==df['02'].index, 'inner').\\\n",
    "    join(df['04'], df['94'].index==df['04'].index, 'inner').\\\n",
    "    join(df['06'], df['94'].index==df['06'].index, 'inner').\\\n",
    "    join(df['08'], df['94'].index==df['08'].index, 'inner').\\\n",
    "    join(df['10'], df['94'].index==df['10'].index, 'inner').\\\n",
    "    join(df['12'], df['94'].index==df['12'].index, 'inner').\\\n",
    "    join(df['14'], df['94'].index==df['14'].index, 'inner').\\\n",
    "    join(df['16'], df['94'].index==df['16'].index, 'inner').\\\n",
    "    join(df['18'], df['94'].index==df['18'].index, 'inner').\\\n",
    "    join(df['20'], df['94'].index==df['20'].index, 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe74dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201c4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_names = [df['94'].index, df['94'].Categories, df['94'].Total_Population_1994, \n",
    "                df['96'].Total_Population_1996, df['98'].Total_Population_1998,\n",
    "                df['00'].Total_Population_2000,df['02'].Total_Population_2002,\n",
    "                df['04'].Total_Population_2004,df['06'].Total_Population_2006,\n",
    "                df['08'].Total_Population_2008,df['10'].Total_Population_2010,\n",
    "                df['12'].Total_Population_2012,df['14'].Total_Population_2014,\n",
    "                df['16'].Total_Population_2016,df['18'].Total_Population_2018,\n",
    "                df['20'].Total_Population_2020\n",
    "               ]\n",
    "\n",
    "\n",
    "pop = full.select(pop_names).\\\n",
    "    withColumnRenamed('Total_Population_1994', '1994').\\\n",
    "    withColumnRenamed('Total_Population_1996', '1996').\\\n",
    "    withColumnRenamed('Total_Population_1998', '1998').\\\n",
    "    withColumnRenamed('Total_Population_2000', '2000').\\\n",
    "    withColumnRenamed('Total_Population_2002', '2002').\\\n",
    "    withColumnRenamed('Total_Population_2004', '2004').\\\n",
    "    withColumnRenamed('Total_Population_2006', '2006').\\\n",
    "    withColumnRenamed('Total_Population_2008', '2008').\\\n",
    "    withColumnRenamed('Total_Population_2010', '2010').\\\n",
    "    withColumnRenamed('Total_Population_2012', '2012').\\\n",
    "    withColumnRenamed('Total_Population_2014', '2014').\\\n",
    "    withColumnRenamed('Total_Population_2016', '2016').\\\n",
    "    withColumnRenamed('Total_Population_2018', '2018').\\\n",
    "    withColumnRenamed('Total_Population_2020', '2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3e7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_names = [df['94'].index, df['94'].Categories, df['94'].Total_Registered_1994, \n",
    "                df['96'].Total_Registered_1996, df['98'].Total_Registered_1998,\n",
    "                df['00'].Total_Registered_2000,df['02'].Total_Registered_2002,\n",
    "                df['04'].Total_Registered_2004,df['06'].Total_Registered_2006,\n",
    "                df['08'].Total_Registered_2008,df['10'].Total_Registered_2010,\n",
    "                df['12'].Total_Registered_2012,df['14'].Total_Registered_2014,\n",
    "                df['16'].Total_Registered_2016,df['18'].Total_Registered_2018,\n",
    "                df['20'].Total_Registered_2020\n",
    "               ]\n",
    "\n",
    "reg = full.select(reg_names).\\\n",
    "    withColumnRenamed('Total_Registered_1994', '1994').\\\n",
    "    withColumnRenamed('Total_Registered_1996', '1996').\\\n",
    "    withColumnRenamed('Total_Registered_1998', '1998').\\\n",
    "    withColumnRenamed('Total_Registered_2000', '2000').\\\n",
    "    withColumnRenamed('Total_Registered_2002', '2002').\\\n",
    "    withColumnRenamed('Total_Registered_2004', '2004').\\\n",
    "    withColumnRenamed('Total_Registered_2006', '2006').\\\n",
    "    withColumnRenamed('Total_Registered_2008', '2008').\\\n",
    "    withColumnRenamed('Total_Registered_2010', '2010').\\\n",
    "    withColumnRenamed('Total_Registered_2012', '2012').\\\n",
    "    withColumnRenamed('Total_Registered_2014', '2014').\\\n",
    "    withColumnRenamed('Total_Registered_2016', '2016').\\\n",
    "    withColumnRenamed('Total_Registered_2018', '2018').\\\n",
    "    withColumnRenamed('Total_Registered_2020', '2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "043899e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vot_names = [df['94'].index, df['94'].Categories, df['94'].Total_Voted_1994, \n",
    "                df['96'].Total_Voted_1996, df['98'].Total_Voted_1998,\n",
    "                df['00'].Total_Voted_2000,df['02'].Total_Voted_2002,\n",
    "                df['04'].Total_Voted_2004,df['06'].Total_Voted_2006,\n",
    "                df['08'].Total_Voted_2008,df['10'].Total_Voted_2010,\n",
    "                df['12'].Total_Voted_2012,df['14'].Total_Voted_2014,\n",
    "                df['16'].Total_Voted_2016,df['18'].Total_Voted_2018,\n",
    "                df['20'].Total_Voted_2020\n",
    "               ]\n",
    "\n",
    "vot = full.select(vot_names).\\\n",
    "    withColumnRenamed('Total_Voted_1994', '1994').\\\n",
    "    withColumnRenamed('Total_Voted_1996', '1996').\\\n",
    "    withColumnRenamed('Total_Voted_1998', '1998').\\\n",
    "    withColumnRenamed('Total_Voted_2000', '2000').\\\n",
    "    withColumnRenamed('Total_Voted_2002', '2002').\\\n",
    "    withColumnRenamed('Total_Voted_2004', '2004').\\\n",
    "    withColumnRenamed('Total_Voted_2006', '2006').\\\n",
    "    withColumnRenamed('Total_Voted_2008', '2008').\\\n",
    "    withColumnRenamed('Total_Voted_2010', '2010').\\\n",
    "    withColumnRenamed('Total_Voted_2012', '2012').\\\n",
    "    withColumnRenamed('Total_Voted_2014', '2014').\\\n",
    "    withColumnRenamed('Total_Voted_2016', '2016').\\\n",
    "    withColumnRenamed('Total_Voted_2018', '2018').\\\n",
    "    withColumnRenamed('Total_Voted_2020', '2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f33292c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = full.toPandas()\n",
    "dp.to_csv(\"elections/full.csv\", header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f1bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = pop.toPandas()\n",
    "dp.to_csv(\"elections/pop.csv\", header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236aeeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = reg.toPandas()\n",
    "dp.to_csv(\"elections/reg.csv\", header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c6c605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = vot.toPandas()\n",
    "dp.to_csv(\"elections/vot.csv\", header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46e0b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e54e01c",
   "metadata": {},
   "source": [
    "# Univariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "573eab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import *\n",
    "from collections import OrderedDict \n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24124db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/11 14:11:29 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>elect</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f930e8c2100>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Univariate LR').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6aa6546",
   "metadata": {},
   "source": [
    "## Build datasets for each Univariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "21894ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop=sqlContext.read.csv('elections/pop.csv',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1dc38568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a column of row numbers\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\",\"true\")\n",
    "w=Window.orderBy(lit(1))\n",
    "pop= pop.withColumn(\"_c0\",row_number().over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62ce1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eventually we will drop row numbers and strings.\n",
    "all_columns = pop.columns\n",
    "all_columns.remove('_c0')\n",
    "all_columns.remove('_c1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ba6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to change our categories column:\n",
    "# For example, MALE should be UNITED STATES MALE or ALASKA MALE and so on.\n",
    "\n",
    "categories=pop.rdd.map(lambda x: [x[0],x[1]]).collect()\n",
    "for i in range(1,308,6):\n",
    "    cat = categories[i][1]\n",
    "    if len(cat)>1 and 'TOTAL'in cat:\n",
    "        cat = ' '.join(cat.split()[:-1])\n",
    "    for j in range(1,6):\n",
    "        categories[i+j][1]=cat+' '+categories[i+j][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607156d0",
   "metadata": {},
   "source": [
    "#### The above list of categories is used below for building our dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef41963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93751c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adc3e1a1",
   "metadata": {},
   "source": [
    "### Dictionary of Population PySpark DataFrames for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f5afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "popdict = {}\n",
    "\n",
    "for i in range(1,313):\n",
    "    popcat = pop.filter(pop._c0.isin(1,categories[i][0])).\\\n",
    "            select(all_columns).\\\n",
    "            toPandas().\\\n",
    "            transpose().\\\n",
    "            apply(pd.to_numeric)\n",
    "    \n",
    "    popdict[i] = spark.createDataFrame(popcat).\\\n",
    "            withColumnRenamed('0','year').\\\n",
    "            withColumnRenamed('1',categories[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1983e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,313):\n",
    "    dp = popdict[i].toPandas()\n",
    "    name = '-'.join(categories[i][1].split())+'.csv'\n",
    "    dp.to_csv(\"elections/PopulationFolders/\"+name, header=True, index = False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f956282",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=sqlContext.read.csv('elections/reg.csv',header=False)\n",
    "reg= reg.withColumn(\"_c0\",row_number().over(w))\n",
    "regdict = {}\n",
    "\n",
    "for i in range(1,313):\n",
    "    regcat = reg.filter(reg._c0.isin(1,categories[i][0])).\\\n",
    "            select(all_columns).\\\n",
    "            toPandas().\\\n",
    "            transpose().\\\n",
    "            apply(pd.to_numeric)\n",
    "    \n",
    "    regdict[i] = spark.createDataFrame(regcat).\\\n",
    "            withColumnRenamed('0','year').\\\n",
    "            withColumnRenamed('1',categories[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,313):\n",
    "    dp = regdict[i].toPandas()\n",
    "    name = '-'.join(categories[i][1].split())+'.csv'\n",
    "    dp.to_csv(\"elections/RegistrationFolders/\"+name, header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590854c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vot=sqlContext.read.csv('elections/vot.csv',header=False)\n",
    "vot= vot.withColumn(\"_c0\",row_number().over(w))\n",
    "votdict = {}\n",
    "\n",
    "for i in range(1,313):\n",
    "    votcat = vot.filter(vot._c0.isin(1,categories[i][0])).\\\n",
    "            select(all_columns).\\\n",
    "            toPandas().\\\n",
    "            transpose().\\\n",
    "            apply(pd.to_numeric)\n",
    "    \n",
    "    votdict[i] = spark.createDataFrame(votcat).\\\n",
    "            withColumnRenamed('0','year').\\\n",
    "            withColumnRenamed('1',categories[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f904d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,313):\n",
    "    dp = votdict[i].toPandas()\n",
    "    name = '-'.join(categories[i][1].split())+'.csv'\n",
    "    dp.to_csv(\"elections/VotingFolders/\"+name, header=True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bd49a8",
   "metadata": {},
   "source": [
    "### Univariate Linear Regression on each piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da59212a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/11 18:17:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umaiyer/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local[*]\", \"elect\")\n",
    "from pyspark import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edcb7deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import BooleanType,DateType,IntegerType,StringType, DoubleType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict \n",
    "\n",
    "import pandas as pd\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e7d391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/11 18:18:09 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.6:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>elect</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9eb76a5100>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Univariate LR').getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d171b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6340d0",
   "metadata": {},
   "source": [
    "### The following list of categories was obtained above. We will use this again below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c6eddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [[1, 'Categories'],\n",
    " [2, 'UNITED STATES'],\n",
    " [3, 'UNITED STATES MALE'],\n",
    " [4, 'UNITED STATES FEMALE'],\n",
    " [5, 'UNITED STATES WHITE'],\n",
    " [6, 'UNITED STATES BLACK'],\n",
    " [7, 'UNITED STATES HISPANIC ORIGIN'],\n",
    " [8, 'ALABAMA TOTAL'],\n",
    " [9, 'ALABAMA MALE'],\n",
    " [10, 'ALABAMA FEMALE'],\n",
    " [11, 'ALABAMA WHITE'],\n",
    " [12, 'ALABAMA BLACK'],\n",
    " [13, 'ALABAMA HISPANIC ORIGIN'],\n",
    " [14, 'ALASKA TOTAL'],\n",
    " [15, 'ALASKA MALE'],\n",
    " [16, 'ALASKA FEMALE'],\n",
    " [17, 'ALASKA WHITE'],\n",
    " [18, 'ALASKA BLACK'],\n",
    " [19, 'ALASKA HISPANIC ORIGIN'],\n",
    " [20, 'ARIZONA TOTAL'],\n",
    " [21, 'ARIZONA MALE'],\n",
    " [22, 'ARIZONA FEMALE'],\n",
    " [23, 'ARIZONA WHITE'],\n",
    " [24, 'ARIZONA BLACK'],\n",
    " [25, 'ARIZONA HISPANIC ORIGIN'],\n",
    " [26, 'ARKANSAS TOTAL'],\n",
    " [27, 'ARKANSAS MALE'],\n",
    " [28, 'ARKANSAS FEMALE'],\n",
    " [29, 'ARKANSAS WHITE'],\n",
    " [30, 'ARKANSAS BLACK'],\n",
    " [31, 'ARKANSAS HISPANIC ORIGIN'],\n",
    " [32, 'CALIFORNIA TOTAL'],\n",
    " [33, 'CALIFORNIA MALE'],\n",
    " [34, 'CALIFORNIA FEMALE'],\n",
    " [35, 'CALIFORNIA WHITE'],\n",
    " [36, 'CALIFORNIA BLACK'],\n",
    " [37, 'CALIFORNIA HISPANIC ORIGIN'],\n",
    " [38, 'COLORADO TOTAL'],\n",
    " [39, 'COLORADO MALE'],\n",
    " [40, 'COLORADO FEMALE'],\n",
    " [41, 'COLORADO WHITE'],\n",
    " [42, 'COLORADO BLACK'],\n",
    " [43, 'COLORADO HISPANIC ORIGIN'],\n",
    " [44, 'CONNECTICUT TOTAL'],\n",
    " [45, 'CONNECTICUT MALE'],\n",
    " [46, 'CONNECTICUT FEMALE'],\n",
    " [47, 'CONNECTICUT WHITE'],\n",
    " [48, 'CONNECTICUT BLACK'],\n",
    " [49, 'CONNECTICUT HISPANIC ORIGIN'],\n",
    " [50, 'DELAWARE TOTAL'],\n",
    " [51, 'DELAWARE MALE'],\n",
    " [52, 'DELAWARE FEMALE'],\n",
    " [53, 'DELAWARE WHITE'],\n",
    " [54, 'DELAWARE BLACK'],\n",
    " [55, 'DELAWARE HISPANIC ORIGIN'],\n",
    " [56, 'DISTRICT OF COLUMBIA TOTAL'],\n",
    " [57, 'DISTRICT OF COLUMBIA MALE'],\n",
    " [58, 'DISTRICT OF COLUMBIA FEMALE'],\n",
    " [59, 'DISTRICT OF COLUMBIA WHITE'],\n",
    " [60, 'DISTRICT OF COLUMBIA BLACK'],\n",
    " [61, 'DISTRICT OF COLUMBIA HISPANIC ORIGIN'],\n",
    " [62, 'FLORIDA TOTAL'],\n",
    " [63, 'FLORIDA MALE'],\n",
    " [64, 'FLORIDA FEMALE'],\n",
    " [65, 'FLORIDA WHITE'],\n",
    " [66, 'FLORIDA BLACK'],\n",
    " [67, 'FLORIDA HISPANIC ORIGIN'],\n",
    " [68, 'GEORGIA TOTAL'],\n",
    " [69, 'GEORGIA MALE'],\n",
    " [70, 'GEORGIA FEMALE'],\n",
    " [71, 'GEORGIA WHITE'],\n",
    " [72, 'GEORGIA BLACK'],\n",
    " [73, 'GEORGIA HISPANIC ORIGIN'],\n",
    " [74, 'HAWAII TOTAL'],\n",
    " [75, 'HAWAII MALE'],\n",
    " [76, 'HAWAII FEMALE'],\n",
    " [77, 'HAWAII WHITE'],\n",
    " [78, 'HAWAII BLACK'],\n",
    " [79, 'HAWAII HISPANIC ORIGIN'],\n",
    " [80, 'IDAHO TOTAL'],\n",
    " [81, 'IDAHO MALE'],\n",
    " [82, 'IDAHO FEMALE'],\n",
    " [83, 'IDAHO WHITE'],\n",
    " [84, 'IDAHO BLACK'],\n",
    " [85, 'IDAHO HISPANIC ORIGIN'],\n",
    " [86, 'ILLINOIS TOTAL'],\n",
    " [87, 'ILLINOIS MALE'],\n",
    " [88, 'ILLINOIS FEMALE'],\n",
    " [89, 'ILLINOIS WHITE'],\n",
    " [90, 'ILLINOIS BLACK'],\n",
    " [91, 'ILLINOIS HISPANIC ORIGIN'],\n",
    " [92, 'INDIANA TOTAL'],\n",
    " [93, 'INDIANA MALE'],\n",
    " [94, 'INDIANA FEMALE'],\n",
    " [95, 'INDIANA WHITE'],\n",
    " [96, 'INDIANA BLACK'],\n",
    " [97, 'INDIANA HISPANIC ORIGIN'],\n",
    " [98, 'IOWA TOTAL'],\n",
    " [99, 'IOWA MALE'],\n",
    " [100, 'IOWA FEMALE'],\n",
    " [101, 'IOWA WHITE'],\n",
    " [102, 'IOWA BLACK'],\n",
    " [103, 'IOWA HISPANIC ORIGIN'],\n",
    " [104, 'KANSAS TOTAL'],\n",
    " [105, 'KANSAS MALE'],\n",
    " [106, 'KANSAS FEMALE'],\n",
    " [107, 'KANSAS WHITE'],\n",
    " [108, 'KANSAS BLACK'],\n",
    " [109, 'KANSAS HISPANIC ORIGIN'],\n",
    " [110, 'KENTUCKY TOTAL'],\n",
    " [111, 'KENTUCKY MALE'],\n",
    " [112, 'KENTUCKY FEMALE'],\n",
    " [113, 'KENTUCKY WHITE'],\n",
    " [114, 'KENTUCKY BLACK'],\n",
    " [115, 'KENTUCKY HISPANIC ORIGIN'],\n",
    " [116, 'LOUISIANA TOTAL'],\n",
    " [117, 'LOUISIANA MALE'],\n",
    " [118, 'LOUISIANA FEMALE'],\n",
    " [119, 'LOUISIANA WHITE'],\n",
    " [120, 'LOUISIANA BLACK'],\n",
    " [121, 'LOUISIANA HISPANIC ORIGIN'],\n",
    " [122, 'MAINE TOTAL'],\n",
    " [123, 'MAINE MALE'],\n",
    " [124, 'MAINE FEMALE'],\n",
    " [125, 'MAINE WHITE'],\n",
    " [126, 'MAINE BLACK'],\n",
    " [127, 'MAINE HISPANIC ORIGIN'],\n",
    " [128, 'MARYLAND TOTAL'],\n",
    " [129, 'MARYLAND MALE'],\n",
    " [130, 'MARYLAND FEMALE'],\n",
    " [131, 'MARYLAND WHITE'],\n",
    " [132, 'MARYLAND BLACK'],\n",
    " [133, 'MARYLAND HISPANIC ORIGIN'],\n",
    " [134, 'MASSACHUSETTS TOTAL'],\n",
    " [135, 'MASSACHUSETTS MALE'],\n",
    " [136, 'MASSACHUSETTS FEMALE'],\n",
    " [137, 'MASSACHUSETTS WHITE'],\n",
    " [138, 'MASSACHUSETTS BLACK'],\n",
    " [139, 'MASSACHUSETTS HISPANIC ORIGIN'],\n",
    " [140, 'MICHIGAN TOTAL'],\n",
    " [141, 'MICHIGAN MALE'],\n",
    " [142, 'MICHIGAN FEMALE'],\n",
    " [143, 'MICHIGAN WHITE'],\n",
    " [144, 'MICHIGAN BLACK'],\n",
    " [145, 'MICHIGAN HISPANIC ORIGIN'],\n",
    " [146, 'MINNESOTA TOTAL'],\n",
    " [147, 'MINNESOTA MALE'],\n",
    " [148, 'MINNESOTA FEMALE'],\n",
    " [149, 'MINNESOTA WHITE'],\n",
    " [150, 'MINNESOTA BLACK'],\n",
    " [151, 'MINNESOTA HISPANIC ORIGIN'],\n",
    " [152, 'MISSISSIPPI TOTAL'],\n",
    " [153, 'MISSISSIPPI MALE'],\n",
    " [154, 'MISSISSIPPI FEMALE'],\n",
    " [155, 'MISSISSIPPI WHITE'],\n",
    " [156, 'MISSISSIPPI BLACK'],\n",
    " [157, 'MISSISSIPPI HISPANIC ORIGIN'],\n",
    " [158, 'MISSOURI TOTAL'],\n",
    " [159, 'MISSOURI MALE'],\n",
    " [160, 'MISSOURI FEMALE'],\n",
    " [161, 'MISSOURI WHITE'],\n",
    " [162, 'MISSOURI BLACK'],\n",
    " [163, 'MISSOURI HISPANIC ORIGIN'],\n",
    " [164, 'MONTANA TOTAL'],\n",
    " [165, 'MONTANA MALE'],\n",
    " [166, 'MONTANA FEMALE'],\n",
    " [167, 'MONTANA WHITE'],\n",
    " [168, 'MONTANA BLACK'],\n",
    " [169, 'MONTANA HISPANIC ORIGIN'],\n",
    " [170, 'NEBRASKA TOTAL'],\n",
    " [171, 'NEBRASKA MALE'],\n",
    " [172, 'NEBRASKA FEMALE'],\n",
    " [173, 'NEBRASKA WHITE'],\n",
    " [174, 'NEBRASKA BLACK'],\n",
    " [175, 'NEBRASKA HISPANIC ORIGIN'],\n",
    " [176, 'NEVADA TOTAL'],\n",
    " [177, 'NEVADA MALE'],\n",
    " [178, 'NEVADA FEMALE'],\n",
    " [179, 'NEVADA WHITE'],\n",
    " [180, 'NEVADA BLACK'],\n",
    " [181, 'NEVADA HISPANIC ORIGIN'],\n",
    " [182, 'NEW HAMPSHIRE TOTAL'],\n",
    " [183, 'NEW HAMPSHIRE MALE'],\n",
    " [184, 'NEW HAMPSHIRE FEMALE'],\n",
    " [185, 'NEW HAMPSHIRE WHITE'],\n",
    " [186, 'NEW HAMPSHIRE BLACK'],\n",
    " [187, 'NEW HAMPSHIRE HISPANIC ORIGIN'],\n",
    " [188, 'NEW JERSEY TOTAL'],\n",
    " [189, 'NEW JERSEY MALE'],\n",
    " [190, 'NEW JERSEY FEMALE'],\n",
    " [191, 'NEW JERSEY WHITE'],\n",
    " [192, 'NEW JERSEY BLACK'],\n",
    " [193, 'NEW JERSEY HISPANIC ORIGIN'],\n",
    " [194, 'NEW MEXICO TOTAL'],\n",
    " [195, 'NEW MEXICO MALE'],\n",
    " [196, 'NEW MEXICO FEMALE'],\n",
    " [197, 'NEW MEXICO WHITE'],\n",
    " [198, 'NEW MEXICO BLACK'],\n",
    " [199, 'NEW MEXICO HISPANIC ORIGIN'],\n",
    " [200, 'NEW YORK TOTAL'],\n",
    " [201, 'NEW YORK MALE'],\n",
    " [202, 'NEW YORK FEMALE'],\n",
    " [203, 'NEW YORK WHITE'],\n",
    " [204, 'NEW YORK BLACK'],\n",
    " [205, 'NEW YORK HISPANIC ORIGIN'],\n",
    " [206, 'NORTH CAROLINA TOTAL'],\n",
    " [207, 'NORTH CAROLINA MALE'],\n",
    " [208, 'NORTH CAROLINA FEMALE'],\n",
    " [209, 'NORTH CAROLINA WHITE'],\n",
    " [210, 'NORTH CAROLINA BLACK'],\n",
    " [211, 'NORTH CAROLINA HISPANIC ORIGIN'],\n",
    " [212, 'NORTH DAKOTA TOTAL'],\n",
    " [213, 'NORTH DAKOTA MALE'],\n",
    " [214, 'NORTH DAKOTA FEMALE'],\n",
    " [215, 'NORTH DAKOTA WHITE'],\n",
    " [216, 'NORTH DAKOTA BLACK'],\n",
    " [217, 'NORTH DAKOTA HISPANIC ORIGIN'],\n",
    " [218, 'OHIO TOTAL'],\n",
    " [219, 'OHIO MALE'],\n",
    " [220, 'OHIO FEMALE'],\n",
    " [221, 'OHIO WHITE'],\n",
    " [222, 'OHIO BLACK'],\n",
    " [223, 'OHIO HISPANIC ORIGIN'],\n",
    " [224, 'OKLAHOMA TOTAL'],\n",
    " [225, 'OKLAHOMA MALE'],\n",
    " [226, 'OKLAHOMA FEMALE'],\n",
    " [227, 'OKLAHOMA WHITE'],\n",
    " [228, 'OKLAHOMA BLACK'],\n",
    " [229, 'OKLAHOMA HISPANIC ORIGIN'],\n",
    " [230, 'OREGON TOTAL'],\n",
    " [231, 'OREGON MALE'],\n",
    " [232, 'OREGON FEMALE'],\n",
    " [233, 'OREGON WHITE'],\n",
    " [234, 'OREGON BLACK'],\n",
    " [235, 'OREGON HISPANIC ORIGIN'],\n",
    " [236, 'PENNSYLVANIA TOTAL'],\n",
    " [237, 'PENNSYLVANIA MALE'],\n",
    " [238, 'PENNSYLVANIA FEMALE'],\n",
    " [239, 'PENNSYLVANIA WHITE'],\n",
    " [240, 'PENNSYLVANIA BLACK'],\n",
    " [241, 'PENNSYLVANIA HISPANIC ORIGIN'],\n",
    " [242, 'RHODE ISLAND TOTAL'],\n",
    " [243, 'RHODE ISLAND MALE'],\n",
    " [244, 'RHODE ISLAND FEMALE'],\n",
    " [245, 'RHODE ISLAND WHITE'],\n",
    " [246, 'RHODE ISLAND BLACK'],\n",
    " [247, 'RHODE ISLAND HISPANIC ORIGIN'],\n",
    " [248, 'SOUTH CAROLINA TOTAL'],\n",
    " [249, 'SOUTH CAROLINA MALE'],\n",
    " [250, 'SOUTH CAROLINA FEMALE'],\n",
    " [251, 'SOUTH CAROLINA WHITE'],\n",
    " [252, 'SOUTH CAROLINA BLACK'],\n",
    " [253, 'SOUTH CAROLINA HISPANIC ORIGIN'],\n",
    " [254, 'SOUTH DAKOTA TOTAL'],\n",
    " [255, 'SOUTH DAKOTA MALE'],\n",
    " [256, 'SOUTH DAKOTA FEMALE'],\n",
    " [257, 'SOUTH DAKOTA WHITE'],\n",
    " [258, 'SOUTH DAKOTA BLACK'],\n",
    " [259, 'SOUTH DAKOTA HISPANIC ORIGIN'],\n",
    " [260, 'TENNESSEE TOTAL'],\n",
    " [261, 'TENNESSEE MALE'],\n",
    " [262, 'TENNESSEE FEMALE'],\n",
    " [263, 'TENNESSEE WHITE'],\n",
    " [264, 'TENNESSEE BLACK'],\n",
    " [265, 'TENNESSEE HISPANIC ORIGIN'],\n",
    " [266, 'TEXAS TOTAL'],\n",
    " [267, 'TEXAS MALE'],\n",
    " [268, 'TEXAS FEMALE'],\n",
    " [269, 'TEXAS WHITE'],\n",
    " [270, 'TEXAS BLACK'],\n",
    " [271, 'TEXAS HISPANIC ORIGIN'],\n",
    " [272, 'UTAH TOTAL'],\n",
    " [273, 'UTAH MALE'],\n",
    " [274, 'UTAH FEMALE'],\n",
    " [275, 'UTAH WHITE'],\n",
    " [276, 'UTAH BLACK'],\n",
    " [277, 'UTAH HISPANIC ORIGIN'],\n",
    " [278, 'VERMONT TOTAL'],\n",
    " [279, 'VERMONT MALE'],\n",
    " [280, 'VERMONT FEMALE'],\n",
    " [281, 'VERMONT WHITE'],\n",
    " [282, 'VERMONT BLACK'],\n",
    " [283, 'VERMONT HISPANIC ORIGIN'],\n",
    " [284, 'VIRGINIA TOTAL'],\n",
    " [285, 'VIRGINIA MALE'],\n",
    " [286, 'VIRGINIA FEMALE'],\n",
    " [287, 'VIRGINIA WHITE'],\n",
    " [288, 'VIRGINIA BLACK'],\n",
    " [289, 'VIRGINIA HISPANIC ORIGIN'],\n",
    " [290, 'WASHINGTON TOTAL'],\n",
    " [291, 'WASHINGTON MALE'],\n",
    " [292, 'WASHINGTON FEMALE'],\n",
    " [293, 'WASHINGTON WHITE'],\n",
    " [294, 'WASHINGTON BLACK'],\n",
    " [295, 'WASHINGTON HISPANIC ORIGIN'],\n",
    " [296, 'WEST VIRGINIA TOTAL'],\n",
    " [297, 'WEST VIRGINIA MALE'],\n",
    " [298, 'WEST VIRGINIA FEMALE'],\n",
    " [299, 'WEST VIRGINIA WHITE'],\n",
    " [300, 'WEST VIRGINIA BLACK'],\n",
    " [301, 'WEST VIRGINIA HISPANIC ORIGIN'],\n",
    " [302, 'WISCONSIN TOTAL'],\n",
    " [303, 'WISCONSIN MALE'],\n",
    " [304, 'WISCONSIN FEMALE'],\n",
    " [305, 'WISCONSIN WHITE'],\n",
    " [306, 'WISCONSIN BLACK'],\n",
    " [307, 'WISCONSIN HISPANIC ORIGIN'],\n",
    " [308, 'WYOMING TOTAL'],\n",
    " [309, 'WYOMING MALE'],\n",
    " [310, 'WYOMING FEMALE'],\n",
    " [311, 'WYOMING WHITE'],\n",
    " [312, 'WYOMING BLACK'],\n",
    " [313, 'WYOMING HISPANIC ORIGIN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bf641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a55cc1c2",
   "metadata": {},
   "source": [
    "### Future Years to predict our numbers for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d81b302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data=[2022.0,2024.0,2026.0,2028.0,2030.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e04f999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df = spark.createDataFrame(future_data, DoubleType()).withColumnRenamed('value','year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde18946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbea8e48",
   "metadata": {},
   "source": [
    "### Building predictions for populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a14907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['year'], outputCol='features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,313):\n",
    "    \n",
    "    name = '-'.join(categories[i][1].split())+'.csv'\n",
    "    dp = sqlContext.read.csv(\"elections/PopulationFolders/\"+name, header=True)\n",
    "    dp = dp.na.fill(value = '0',subset=[categories[i][1]])\n",
    "    dp = dp.withColumn(\"year\", dp[\"year\"].cast(DoubleType())).\\\n",
    "        withColumn(categories[i][1], dp[categories[i][1]].cast(DoubleType()))\n",
    "    \n",
    "    \n",
    "    dp_assembled = assembler.transform(dp).select(['features',categories[i][1]])\n",
    "    lr = LinearRegression(maxIter=10, labelCol=categories[i][1])\n",
    "    lrModel = lr.fit(dp_assembled)\n",
    "    \n",
    "    x = lrModel.transform(assembler.transform(future_df))\n",
    "    future = dp.union(x.select('year','prediction'))\n",
    "\n",
    "    future = future.withColumn(\"year\", future[\"year\"].cast(IntegerType())).\\\n",
    "    withColumn(categories[i][1], future[categories[i][1]].cast(IntegerType())).\\\n",
    "    withColumnRenamed(categories[i][1],categories[i][1]+'/Predictions')\n",
    "    \n",
    "    future.toPandas().to_csv(\"elections/PopulationWithPredictions/\"+name, header=True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8930d71",
   "metadata": {},
   "source": [
    "### Building Predictions for Registrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6a904464",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['year'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,313):\n",
    "    \n",
    "    name = '-'.join(categories[i][1].split())+'.csv'\n",
    "    dp = sqlContext.read.csv(\"elections/RegistrationFolders/\"+name, header=True)\n",
    "    dp = dp.na.fill(value = '0',subset=[categories[i][1]])\n",
    "    dp = dp.withColumn(\"year\", dp[\"year\"].cast(DoubleType())).\\\n",
    "        withColumn(categories[i][1], dp[categories[i][1]].cast(DoubleType()))\n",
    "    \n",
    "    \n",
    "    dp_assembled = assembler.transform(dp).select(['features',categories[i][1]])\n",
    "    lr = LinearRegression(maxIter=10, labelCol=categories[i][1])\n",
    "    lrModel = lr.fit(dp_assembled)\n",
    "    \n",
    "    x = lrModel.transform(assembler.transform(future_df))\n",
    "    future = dp.union(x.select('year','prediction'))\n",
    "\n",
    "    future = future.withColumn(\"year\", future[\"year\"].cast(IntegerType())).\\\n",
    "    withColumn(categories[i][1], future[categories[i][1]].cast(IntegerType())).\\\n",
    "    withColumnRenamed(categories[i][1],categories[i][1]+'/Predictions')\n",
    "    \n",
    "    future.toPandas().to_csv(\"elections/RegistrationWithPredictions/\"+name, header=True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1ca59",
   "metadata": {},
   "source": [
    "### Building Predictions for Votings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "83c589cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['year'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,313):\n",
    "    \n",
    "    name = '-'.join(categories[i][1].split())+'.csv'\n",
    "    dp = sqlContext.read.csv(\"elections/VotingFolders/\"+name, header=True)\n",
    "    dp = dp.na.fill(value = '0',subset=[categories[i][1]])\n",
    "    dp = dp.withColumn(\"year\", dp[\"year\"].cast(DoubleType())).\\\n",
    "        withColumn(categories[i][1], dp[categories[i][1]].cast(DoubleType()))\n",
    "    \n",
    "    \n",
    "    dp_assembled = assembler.transform(dp).select(['features',categories[i][1]])\n",
    "    lr = LinearRegression(maxIter=10, labelCol=categories[i][1])\n",
    "    lrModel = lr.fit(dp_assembled)\n",
    "    \n",
    "    x = lrModel.transform(assembler.transform(future_df))\n",
    "    future = dp.union(x.select('year','prediction'))\n",
    "\n",
    "    future = future.withColumn(\"year\", future[\"year\"].cast(IntegerType())).\\\n",
    "    withColumn(categories[i][1], future[categories[i][1]].cast(IntegerType())).\\\n",
    "    withColumnRenamed(categories[i][1],categories[i][1]+'/Predictions')\n",
    "    \n",
    "    future.toPandas().to_csv(\"elections/VotingWithPredictions/\"+name, header=True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95adb263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51187fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = dict(categories)\n",
    "df = pd.DataFrame.from_dict(mydict,orient='index')\n",
    "df.to_csv(\"elections/categories.csv\", header=False, index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8099080a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf818c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641671b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb4e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb415848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3feb1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e459950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb48db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df0cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b199ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2565533f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839dfc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64885ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f24477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
